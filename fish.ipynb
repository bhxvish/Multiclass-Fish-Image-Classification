{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vncDsAP0Gaoa"
      },
      "source": [
        "# **Project Name**    - Multiclass Fish Image Classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beRrZCGUAJYm"
      },
      "source": [
        "##### **Project Type**    - Image Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 - S Bhavish**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJNUwmbgGyua"
      },
      "source": [
        "# **Project Summary -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6v_1wHtG2nS"
      },
      "source": [
        "This project focuses on building an automated image classification system capable of identifying different fish species from photographs using deep learning. High-quality images are organized into distinct class folders, which enables both custom convolutional neural networks (CNNs) and transfer learning approaches (like MobileNetV2) to learn subtle visual differences between species. The workflow covers all stages: data preprocessing, augmentation, model training, evaluation, and deployment. To make the system practical and accessible, a Streamlit web app has been developed where users can easily upload fish images and receive predictions, with class names automatically extracted from their data folders. The app allows seamless model switching and displays interpretive results, such as confidence scores and class probability charts. This end-to-end approach is robust, extensible (simply add new class folders to support more species), and user-friendly, making it well-suited for applications in biodiversity research, fisheries, education, and hobbyist activities. Ultimately, the project demonstrates a practical, modular pipeline that makes advanced computer vision tools directly usable in real-world fish identification tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6K7xa23Elo4"
      },
      "source": [
        "# **GitHub Link -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1o69JH3Eqqn"
      },
      "source": [
        "https://github.com/bhxvish/Multiclass-Fish-Image-Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQaldy8SH6Dl"
      },
      "source": [
        "# **Problem Statement**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpeJGUA3kjGy"
      },
      "source": [
        "**This project focuses on classifying fish images into multiple categories using deep learning models. The task involves training a CNN from scratch and leveraging transfer learning with pre-trained models to enhance performance. The project also includes saving models for later use and deploying a Streamlit application to predict fish categories from user-uploaded images.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDgbUHAGgjLW"
      },
      "source": [
        "# **General Guidelines** : -  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      },
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOySms-4Od-2"
      },
      "source": [
        "# **Import Libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EgsA90r9OjXJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yzCRT6VPK-o"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_D1mSOhiPPY2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6225 images belonging to 11 classes.\n",
            "Found 1092 images belonging to 11 classes.\n",
            "Found 3187 images belonging to 11 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Path to training, validation, and test dataset folders\n",
        "# Each folder should contain subfolders for each class\n",
        "train_dir = \"Dataset/data/train\"\n",
        "val_dir = \"Dataset/data/val\"\n",
        "test_dir = \"Dataset/data/test\"\n",
        "\n",
        "# Target image size for the model (width, height)\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "# Number of images to load in each batch\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create an ImageDataGenerator for training data with augmentation\n",
        "# Augmentation helps the model generalize better by applying random transformations\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,              # Normalize pixel values from [0,255] to [0,1]\n",
        "    rotation_range=20,           # Randomly rotate images up to 20 degrees\n",
        "    width_shift_range=0.10,      # Randomly shift images horizontally by up to 10% of width\n",
        "    height_shift_range=0.10,     # Randomly shift images vertically by up to 10% of height\n",
        "    zoom_range=0.15,             # Randomly zoom into images by up to 15%\n",
        "    horizontal_flip=True         # Randomly flip images horizontally\n",
        ")\n",
        "\n",
        "# Create an ImageDataGenerator for validation data without augmentation\n",
        "# Only rescaling is applied to keep validation data consistent\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create an ImageDataGenerator for test data without augmentation\n",
        "# Only rescaling is applied; shuffle is disabled to keep prediction order consistent\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load training images from the directory using the training data generator\n",
        "# Images will be resized to IMG_SIZE and loaded in batches of BATCH_SIZE\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,                  # Path to training data\n",
        "    target_size=IMG_SIZE,       # Resize images to IMG_SIZE\n",
        "    batch_size=BATCH_SIZE,      # Number of images per batch\n",
        "    class_mode=\"categorical\"    # For multi-class classification\n",
        ")\n",
        "\n",
        "# Load validation images from the directory using the validation data generator\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    val_dir,                    # Path to validation data\n",
        "    target_size=IMG_SIZE,       # Resize images to IMG_SIZE\n",
        "    batch_size=BATCH_SIZE,      # Number of images per batch\n",
        "    class_mode=\"categorical\"    # Multi-class classification\n",
        ")\n",
        "\n",
        "# Load test images from the directory using the test data generator\n",
        "# shuffle=False ensures predictions match the order of the test files\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    test_dir,                   # Path to test data\n",
        "    target_size=IMG_SIZE,       # Resize images to IMG_SIZE\n",
        "    batch_size=BATCH_SIZE,      # Number of images per batch\n",
        "    class_mode=\"categorical\",   # Multi-class classification\n",
        "    shuffle=False               # Keep order for evaluation/prediction\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBjW3J6GPSgi"
      },
      "source": [
        "# **Model Building (CNN from Scratch)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T68P8VThP8hr"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">11,075,712</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,419</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m11,075,712\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │         \u001b[38;5;34m1,419\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,170,379</span> (42.61 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,170,379\u001b[0m (42.61 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,170,379</span> (42.61 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,170,379\u001b[0m (42.61 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Build a Sequential CNN model for image classification\n",
        "model = tf.keras.models.Sequential([\n",
        "    # First convolutional layer:\n",
        "    # - 32 filters\n",
        "    # - Kernel size: (3,3)\n",
        "    # - Activation function: ReLU\n",
        "    # - Input shape: (height, width, 3 channels) from IMG_SIZE\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=IMG_SIZE + (3,)),\n",
        "\n",
        "    # First max pooling layer to reduce spatial dimensions (downsampling)\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # Second convolutional layer:\n",
        "    # - 64 filters for more feature maps\n",
        "    # - Kernel size: (3,3)\n",
        "    # - Activation: ReLU\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "\n",
        "    # Second pooling layer\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # Third convolutional layer:\n",
        "    # - 128 filters for capturing more complex patterns\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "\n",
        "    # Third pooling layer\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # Flatten layer to convert 2D feature maps into a 1D vector for dense layers\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Fully connected (dense) layer with 128 neurons and ReLU activation\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "\n",
        "    # Output layer:\n",
        "    # - Number of neurons = number of classes in training data\n",
        "    # - Activation: softmax to output probabilities for each class\n",
        "    tf.keras.layers.Dense(train_gen.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model:\n",
        "# - Optimizer: Adam (adaptive learning rate)\n",
        "# - Loss function: categorical crossentropy for multi-class classification\n",
        "# - Metric: accuracy to track performance\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print a summary of the model architecture (layer names, shapes, parameters)\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Djs3jEZBQE2Z"
      },
      "source": [
        "# **Training and Validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_URcsybkQHjH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3153 - loss: 1.9232"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sbhav\\miniconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 1s/step - accuracy: 0.4688 - loss: 1.4873 - val_accuracy: 0.6859 - val_loss: 0.8867\n",
            "Epoch 2/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 382ms/step - accuracy: 0.7375 - loss: 0.7517 - val_accuracy: 0.8526 - val_loss: 0.4317\n",
            "Epoch 3/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 636ms/step - accuracy: 0.8252 - loss: 0.4986 - val_accuracy: 0.9057 - val_loss: 0.3234\n",
            "Epoch 4/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 847ms/step - accuracy: 0.8643 - loss: 0.3938 - val_accuracy: 0.9286 - val_loss: 0.2739\n",
            "Epoch 5/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 850ms/step - accuracy: 0.9020 - loss: 0.3025 - val_accuracy: 0.8947 - val_loss: 0.3114\n",
            "Epoch 6/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 859ms/step - accuracy: 0.8949 - loss: 0.2901 - val_accuracy: 0.9515 - val_loss: 0.1570\n",
            "Epoch 7/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 855ms/step - accuracy: 0.9239 - loss: 0.2142 - val_accuracy: 0.9698 - val_loss: 0.1657\n",
            "Epoch 8/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 860ms/step - accuracy: 0.9367 - loss: 0.1769 - val_accuracy: 0.9588 - val_loss: 0.1434\n",
            "Epoch 9/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 855ms/step - accuracy: 0.9406 - loss: 0.1779 - val_accuracy: 0.9734 - val_loss: 0.1230\n",
            "Epoch 10/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 854ms/step - accuracy: 0.9563 - loss: 0.1299 - val_accuracy: 0.9799 - val_loss: 0.0912\n",
            "Epoch 11/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 863ms/step - accuracy: 0.9569 - loss: 0.1266 - val_accuracy: 0.9698 - val_loss: 0.1466\n",
            "Epoch 12/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 837ms/step - accuracy: 0.9598 - loss: 0.1215 - val_accuracy: 0.9634 - val_loss: 0.1577\n",
            "Epoch 13/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 867ms/step - accuracy: 0.9565 - loss: 0.1411 - val_accuracy: 0.9808 - val_loss: 0.0895\n",
            "Epoch 14/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 761ms/step - accuracy: 0.9672 - loss: 0.0992 - val_accuracy: 0.9734 - val_loss: 0.0999\n",
            "Epoch 15/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 389ms/step - accuracy: 0.9618 - loss: 0.1139 - val_accuracy: 0.9872 - val_loss: 0.0935\n",
            "Epoch 16/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 386ms/step - accuracy: 0.9716 - loss: 0.0853 - val_accuracy: 0.9634 - val_loss: 0.1243\n",
            "Epoch 17/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 449ms/step - accuracy: 0.9561 - loss: 0.1217 - val_accuracy: 0.9487 - val_loss: 0.1900\n",
            "Epoch 18/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 821ms/step - accuracy: 0.9740 - loss: 0.0740 - val_accuracy: 0.9716 - val_loss: 0.1051\n",
            "Epoch 19/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 755ms/step - accuracy: 0.9661 - loss: 0.1034 - val_accuracy: 0.9844 - val_loss: 0.0771\n",
            "Epoch 20/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 733ms/step - accuracy: 0.9838 - loss: 0.0504 - val_accuracy: 0.9808 - val_loss: 0.0886\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=20,\n",
        "    validation_data=val_gen\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZefV_TrQOi2"
      },
      "source": [
        "# **Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GncxLQUtQSd_"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,419</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m163,968\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │         \u001b[38;5;34m1,419\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,423,371</span> (9.24 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,423,371\u001b[0m (9.24 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">165,387</span> (646.04 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m165,387\u001b[0m (646.04 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 393ms/step - accuracy: 0.9052 - loss: 0.3321 - val_accuracy: 0.9625 - val_loss: 0.1227\n",
            "Epoch 2/10\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 375ms/step - accuracy: 0.9791 - loss: 0.0710 - val_accuracy: 0.9689 - val_loss: 0.0865\n",
            "Epoch 3/10\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 322ms/step - accuracy: 0.9870 - loss: 0.0453 - val_accuracy: 0.9844 - val_loss: 0.0499\n",
            "Epoch 4/10\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 321ms/step - accuracy: 0.9910 - loss: 0.0338 - val_accuracy: 0.9826 - val_loss: 0.0442\n",
            "Epoch 5/10\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 320ms/step - accuracy: 0.9894 - loss: 0.0329 - val_accuracy: 0.9808 - val_loss: 0.0534\n",
            "Epoch 6/10\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 329ms/step - accuracy: 0.9924 - loss: 0.0245 - val_accuracy: 0.9771 - val_loss: 0.0687\n",
            "Epoch 7/10\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 329ms/step - accuracy: 0.9910 - loss: 0.0255 - val_accuracy: 0.9844 - val_loss: 0.0548\n",
            "Epoch 8/10\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 347ms/step - accuracy: 0.9933 - loss: 0.0186 - val_accuracy: 0.9799 - val_loss: 0.0515\n",
            "Epoch 9/10\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 357ms/step - accuracy: 0.9904 - loss: 0.0257 - val_accuracy: 0.9835 - val_loss: 0.0447\n",
            "Epoch 10/10\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 355ms/step - accuracy: 0.9912 - loss: 0.0263 - val_accuracy: 0.9844 - val_loss: 0.0696\n"
          ]
        }
      ],
      "source": [
        "# Load the base model: MobileNetV2 pretrained on ImageNet\n",
        "# - input_shape: matches our dataset image size (IMG_SIZE + 3 channels for RGB)\n",
        "# - include_top=False: exclude the default fully connected layers at the top\n",
        "# - weights='imagenet': load pretrained weights from ImageNet\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=IMG_SIZE + (3,), \n",
        "    include_top=False, \n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# Freeze the base model layers so they are not updated during initial training\n",
        "# This preserves the pretrained features\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build the transfer learning model\n",
        "model_tl = tf.keras.Sequential([\n",
        "    # Pretrained base model (feature extractor)\n",
        "    base_model,\n",
        "    \n",
        "    # Global Average Pooling layer:\n",
        "    # Reduces each feature map to a single value by averaging\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    \n",
        "    # Fully connected layer with 128 neurons and ReLU activation\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    \n",
        "    # Output layer:\n",
        "    # - Number of units = number of classes\n",
        "    # - Softmax activation to output probabilities for each class\n",
        "    tf.keras.layers.Dense(train_gen.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model:\n",
        "# - Optimizer: Adam (adaptive learning rate)\n",
        "# - Loss: categorical crossentropy (for multi-class classification)\n",
        "# - Metric: accuracy\n",
        "model_tl.compile(\n",
        "    optimizer='adam', \n",
        "    loss='categorical_crossentropy', \n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Display the model architecture\n",
        "model_tl.summary()\n",
        "\n",
        "# Train the model:\n",
        "# - Use train_gen for training batches\n",
        "# - Validate on val_gen to track performance\n",
        "# - Train for 10 epochs\n",
        "history_tl = model_tl.fit(\n",
        "    train_gen,\n",
        "    epochs=10,\n",
        "    validation_data=val_gen\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5fmj9DtQdIc"
      },
      "source": [
        "# **Evaluation and Comparison**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TaHOF3HRQkYU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 447ms/step - accuracy: 0.9856 - loss: 0.0658\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 168ms/step - accuracy: 0.9893 - loss: 0.0304\n",
            "Custom CNN - Test Accuracy: 0.9855663776397705\n",
            "Transfer Learning - Test Accuracy: 0.9893316626548767\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(test_gen)\n",
        "loss_tl, acc_tl = model_tl.evaluate(test_gen)\n",
        "\n",
        "print(f\"Custom CNN - Test Accuracy: {acc}\")\n",
        "print(f\"Transfer Learning - Test Accuracy: {acc_tl}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyiSsc6nQrrd"
      },
      "source": [
        "# **Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "p_JRMXjxQuqV"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['accuracy'], label='CNN Accuracy')\n",
        "plt.plot(history_tl.history['accuracy'], label='Transfer Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Save Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('fish_cnn_model.h5')\n",
        "model_tl.save('fish_mobilenet_model.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCX9965dhzqZ"
      },
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      },
      "source": [
        "This project successfully demonstrates the application of deep learning techniques for multi-class fish species classification. By leveraging both a custom CNN and transfer learning models such as MobileNetV2, the system achieves robust classification performance.\n",
        "\n",
        "Data preprocessing and augmentation helped improve model generalization, while the evaluation phase provided clear insights into the strengths and weaknesses of each model. The integration with a Streamlit web application makes the solution accessible and user-friendly, allowing real-time image uploads and predictions with confidence scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIfDvo9L0UH2"
      },
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
